{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "challenging-capability",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-14T01:04:56.556773Z",
     "iopub.status.busy": "2021-06-14T01:04:56.556125Z",
     "iopub.status.idle": "2021-06-14T01:05:02.380156Z",
     "shell.execute_reply": "2021-06-14T01:05:02.380900Z",
     "shell.execute_reply.started": "2021-06-14T00:56:22.728433Z"
    },
    "papermill": {
     "duration": 5.857888,
     "end_time": "2021-06-14T01:05:02.381259",
     "exception": false,
     "start_time": "2021-06-14T01:04:56.523371",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import h5py\n",
    "import time\n",
    "from PIL import Image\n",
    "import requests\n",
    "import imageio\n",
    "from io import BytesIO\n",
    "from IPython.display import clear_output\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import imshow\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import datetime, os\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vital-missile",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-14T01:05:02.421988Z",
     "iopub.status.busy": "2021-06-14T01:05:02.421401Z",
     "iopub.status.idle": "2021-06-14T01:05:12.015071Z",
     "shell.execute_reply": "2021-06-14T01:05:12.014288Z",
     "shell.execute_reply.started": "2021-06-14T00:56:28.693862Z"
    },
    "papermill": {
     "duration": 9.614957,
     "end_time": "2021-06-14T01:05:12.015251",
     "exception": false,
     "start_time": "2021-06-14T01:05:02.400294",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Required images are saved as an hdf5 file and uploaded to Kaggle as a Dataset.  \n",
    "# Below saves images from the dataset to a numpy array.\n",
    "hf = h5py.File(\"../input/images/images.hdf5\", \"r\")\n",
    "images = np.array(hf[\"/images\"]).astype(\"uint8\")\n",
    "hf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "natural-contribution",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-14T01:05:12.076891Z",
     "iopub.status.busy": "2021-06-14T01:05:12.076181Z",
     "iopub.status.idle": "2021-06-14T01:05:12.235979Z",
     "shell.execute_reply": "2021-06-14T01:05:12.236453Z",
     "shell.execute_reply.started": "2021-06-14T00:56:37.830128Z"
    },
    "papermill": {
     "duration": 0.20213,
     "end_time": "2021-06-14T01:05:12.236655",
     "exception": false,
     "start_time": "2021-06-14T01:05:12.034525",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "imshow(images[13])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "finished-material",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-14T01:05:12.283692Z",
     "iopub.status.busy": "2021-06-14T01:05:12.282999Z",
     "iopub.status.idle": "2021-06-14T01:05:12.613706Z",
     "shell.execute_reply": "2021-06-14T01:05:12.614293Z",
     "shell.execute_reply.started": "2021-06-14T00:56:38.023922Z"
    },
    "papermill": {
     "duration": 0.357009,
     "end_time": "2021-06-14T01:05:12.614520",
     "exception": false,
     "start_time": "2021-06-14T01:05:12.257511",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# I have manually inspected all of the images and saved the indexes I wanted to remove in a file.\n",
    "# This code block imports those indexes and remove them from the images array.\n",
    "file1 = open('../input/removeindexes/1removeIndexes.txt', 'r')\n",
    "indexes = file1.readlines()\n",
    "indexes = list(map(int, indexes))\n",
    "print(f'Number of images before removal: {len(images)}')\n",
    "images = np.delete(images, indexes, axis = 0)\n",
    "print(f'Number of images after removal: {len(images)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adult-vault",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-14T01:05:12.665479Z",
     "iopub.status.busy": "2021-06-14T01:05:12.664663Z",
     "iopub.status.idle": "2021-06-14T01:05:12.739591Z",
     "shell.execute_reply": "2021-06-14T01:05:12.738942Z",
     "shell.execute_reply.started": "2021-06-14T00:56:38.242577Z"
    },
    "papermill": {
     "duration": 0.104416,
     "end_time": "2021-06-14T01:05:12.739766",
     "exception": false,
     "start_time": "2021-06-14T01:05:12.635350",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.layers import Dense, Conv2DTranspose, LeakyReLU, Reshape, BatchNormalization, Activation, Conv2D, Flatten, Dropout, AveragePooling2D, UpSampling2D, Input, Lambda, GaussianNoise\n",
    "from keras.models import Model, Sequential, load_model\n",
    "from keras.optimizers import Adam, SGD, RMSprop\n",
    "from keras.initializers import RandomNormal\n",
    "from tensorboard.plugins.hparams import api as hp\n",
    "from keras import backend\n",
    "from keras.constraints import Constraint\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "driving-princess",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-14T01:05:12.789650Z",
     "iopub.status.busy": "2021-06-14T01:05:12.787871Z",
     "iopub.status.idle": "2021-06-14T01:05:15.958876Z",
     "shell.execute_reply": "2021-06-14T01:05:15.959409Z",
     "shell.execute_reply.started": "2021-06-14T00:56:38.332889Z"
    },
    "papermill": {
     "duration": 3.19887,
     "end_time": "2021-06-14T01:05:15.959634",
     "exception": false,
     "start_time": "2021-06-14T01:05:12.760764",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def scale_images(images):\n",
    "\t# convert from unit8 to float32\n",
    "\timages = images.astype('float32')\n",
    "\t# scale from [0,255] to [-1,1]\n",
    "\timages = (images - 127.5) / 127.5\n",
    "\treturn images\n",
    "\n",
    "images = scale_images(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "worth-excellence",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-14T01:05:16.065762Z",
     "iopub.status.busy": "2021-06-14T01:05:16.013069Z",
     "iopub.status.idle": "2021-06-14T01:05:21.512091Z",
     "shell.execute_reply": "2021-06-14T01:05:21.512619Z",
     "shell.execute_reply.started": "2021-06-14T00:56:40.849620Z"
    },
    "papermill": {
     "duration": 5.532111,
     "end_time": "2021-06-14T01:05:21.512848",
     "exception": false,
     "start_time": "2021-06-14T01:05:15.980737",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  # TPU detection. No parameters necessary if TPU_NAME environment variable is set. On Kaggle this is always the case.\n",
    "    print('Running on TPU ', tpu.master())\n",
    "except ValueError:\n",
    "    tpu = None\n",
    "\n",
    "if tpu:\n",
    "    tf.config.experimental_connect_to_cluster(tpu)\n",
    "    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
    "    strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
    "else:\n",
    "    strategy = tf.distribute.get_strategy() # default distribution strategy in Tensorflow. Works on CPU and single GPU.\n",
    "\n",
    "print(\"REPLICAS: \", strategy.num_replicas_in_sync)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imposed-gallery",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-14T01:05:21.571054Z",
     "iopub.status.busy": "2021-06-14T01:05:21.570307Z",
     "iopub.status.idle": "2021-06-14T01:05:21.573650Z",
     "shell.execute_reply": "2021-06-14T01:05:21.573079Z",
     "shell.execute_reply.started": "2021-06-14T00:59:47.108507Z"
    },
    "papermill": {
     "duration": 0.038965,
     "end_time": "2021-06-14T01:05:21.573811",
     "exception": false,
     "start_time": "2021-06-14T01:05:21.534846",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Definining the generator model. Commented out codelines are alternative layers that could be used.\n",
    "def image_generator():\n",
    "\n",
    "    generator = Sequential()\n",
    "\n",
    "    generator.add(Dense(256*4*4, input_shape = (100,)))\n",
    "    #generator.add(Dense(512*4*4, input_shape = (100,)))\n",
    "    generator.add(BatchNormalization())\n",
    "    generator.add(LeakyReLU())\n",
    "    generator.add(Reshape((4,4,256)))\n",
    "    #generator.add(Reshape((8,8,512)))\n",
    "\n",
    "    init = RandomNormal(mean=0.0, stddev=0.02)\n",
    "\n",
    "    generator.add(UpSampling2D())\n",
    "    #generator.add(tf.keras.layers.Lambda(lambda x: tf.nn.depth_to_space(x, 2)))\n",
    "    #generator.add(Conv2DTranspose(128,kernel_size=2, strides=2, padding = \"same\", kernel_initializer=init))\n",
    "\n",
    "    generator.add(Conv2D(128, kernel_size=4, padding = \"same\", kernel_initializer=init))\n",
    "    generator.add(BatchNormalization())\n",
    "    #generator.add(Dropout(0.2))\n",
    "    generator.add(LeakyReLU(alpha=0.2))\n",
    "\n",
    "    generator.add(Conv2D(128, kernel_size=4, padding = \"same\", kernel_initializer=init))\n",
    "    generator.add(BatchNormalization())\n",
    "    generator.add(LeakyReLU(alpha=0.2))\n",
    "\n",
    "    generator.add(UpSampling2D())\n",
    "    #generator.add(tf.keras.layers.Lambda(lambda x: tf.nn.depth_to_space(x, 2)))\n",
    "    #generator.add(Conv2DTranspose(128,kernel_size=4, strides=2, padding = \"same\", kernel_initializer=init))\n",
    "\n",
    "    generator.add(Conv2D(128, kernel_size=4, padding = \"same\", kernel_initializer=init))\n",
    "    generator.add(BatchNormalization())\n",
    "    generator.add(LeakyReLU(alpha=0.2))\n",
    "\n",
    "\n",
    "    ##generator.add(Conv2DTranspose(128,kernel_size=4, strides=2, padding = \"same\", kernel_initializer=init))\n",
    "    generator.add(UpSampling2D())\n",
    "    #generator.add(tf.keras.layers.Lambda(lambda x: tf.nn.depth_to_space(x, 2)))\n",
    "\n",
    "    generator.add(Conv2D(128, kernel_size=4, padding = \"same\", kernel_initializer=init))\n",
    "    generator.add(BatchNormalization())\n",
    "    #generator.add(Dropout(0.2))\n",
    "    generator.add(LeakyReLU(alpha=0.2))\n",
    "\n",
    "\n",
    "    ##generator.add(Conv2DTranspose(128,kernel_size=4, strides=2, padding = \"same\", kernel_initializer=init))\n",
    "    generator.add(UpSampling2D())\n",
    "    #generator.add(tf.keras.layers.Lambda(lambda x: tf.nn.depth_to_space(x, 2)))\n",
    "\n",
    "    generator.add(Conv2D(128, kernel_size=4, padding = \"same\", kernel_initializer=init))\n",
    "    #generator.add(BatchNormalization())\n",
    "    generator.add(LeakyReLU(alpha=0.2))\n",
    "\n",
    "    generator.add(Conv2D(3,kernel_size=4, padding = \"same\", activation='tanh', kernel_initializer=init))\n",
    "\n",
    "    return generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pregnant-daniel",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-14T01:05:21.623775Z",
     "iopub.status.busy": "2021-06-14T01:05:21.623116Z",
     "iopub.status.idle": "2021-06-14T01:05:23.608323Z",
     "shell.execute_reply": "2021-06-14T01:05:23.608819Z",
     "shell.execute_reply.started": "2021-06-14T00:59:49.995532Z"
    },
    "papermill": {
     "duration": 2.013102,
     "end_time": "2021-06-14T01:05:23.609010",
     "exception": false,
     "start_time": "2021-06-14T01:05:21.595908",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# For TPU Training\n",
    "with strategy.scope():\n",
    "    generator_model = image_generator()\n",
    "    generator_model.summary()\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "# For GPU Training\n",
    "generator_model = image_generator()\n",
    "generator_model.summary()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "addressed-norway",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-14T01:05:23.662397Z",
     "iopub.status.busy": "2021-06-14T01:05:23.661637Z",
     "iopub.status.idle": "2021-06-14T01:05:23.665300Z",
     "shell.execute_reply": "2021-06-14T01:05:23.665774Z",
     "shell.execute_reply.started": "2021-06-14T00:56:48.322681Z"
    },
    "papermill": {
     "duration": 0.034516,
     "end_time": "2021-06-14T01:05:23.665977",
     "exception": false,
     "start_time": "2021-06-14T01:05:23.631461",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_input_data(n_samples):\n",
    "  X = np.random.randn(100 * n_samples)\n",
    "  X = X.reshape(n_samples, 100)\n",
    "  return X\n",
    "\n",
    "def create_fake_data(generator_model, n_samples):\n",
    "  input = generate_input_data(n_samples)\n",
    "  X = generator_model.predict(input)\n",
    "  #y = np.zeros((n_samples, 1))\n",
    "  y = np.ones((n_samples, 1))\n",
    "  return X,y\n",
    "\n",
    "'''\n",
    "# implementation of wasserstein loss\n",
    "def wasserstein_loss(y_true, y_pred):\n",
    "    return backend.mean(y_true * y_pred)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unsigned-malaysia",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-14T01:05:23.720574Z",
     "iopub.status.busy": "2021-06-14T01:05:23.719766Z",
     "iopub.status.idle": "2021-06-14T01:05:23.735307Z",
     "shell.execute_reply": "2021-06-14T01:05:23.734712Z",
     "shell.execute_reply.started": "2021-06-14T00:59:55.138989Z"
    },
    "papermill": {
     "duration": 0.046609,
     "end_time": "2021-06-14T01:05:23.735475",
     "exception": false,
     "start_time": "2021-06-14T01:05:23.688866",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Definining the discriminator model. Commented out codelines are alternative layers that could be used.\n",
    "def image_discriminator():\n",
    "    # weight initialization\n",
    "    init = RandomNormal(stddev=0.02)\n",
    "\n",
    "    discriminator = Sequential()\n",
    "    discriminator.add(Conv2D(128, kernel_size=4, padding = \"same\", input_shape = (64,64,3), kernel_initializer=init))\n",
    "    discriminator.add(LeakyReLU(alpha=0.2))\n",
    "    #discriminator.add(Dropout(0.4))\n",
    "    \n",
    "\n",
    "    discriminator.add(Conv2D(128, kernel_size=4,strides=(2,2), padding = \"same\", kernel_initializer=init))\n",
    "    #discriminator.add(AveragePooling2D(pool_size=(2, 2)))\n",
    "    #discriminator.add(BatchNormalization())\n",
    "    #discriminator.add(GaussianNoise(0.2))\n",
    "    discriminator.add(LeakyReLU(alpha=0.2))\n",
    "    discriminator.add(Dropout(0.4))\n",
    "    \n",
    "\n",
    "    discriminator.add(Conv2D(128, kernel_size=4,strides=(2,2), padding = \"same\", kernel_initializer=init))\n",
    "    #discriminator.add(AveragePooling2D(pool_size=(2, 2)))\n",
    "    #discriminator.add(BatchNormalization())\n",
    "    #discriminator.add(GaussianNoise(0.2))\n",
    "    discriminator.add(LeakyReLU(alpha=0.2))\n",
    "    discriminator.add(Dropout(0.4))\n",
    "\n",
    "\n",
    "    discriminator.add(Conv2D(128, kernel_size=4,strides=(2,2), padding = \"same\", kernel_initializer=init))\n",
    "    #discriminator.add(BatchNormalization())\n",
    "    #discriminator.add(GaussianNoise(0.2))\n",
    "    discriminator.add(LeakyReLU(alpha=0.2))\n",
    "    discriminator.add(Dropout(0.4))\n",
    "    \n",
    "\n",
    "    discriminator.add(Conv2D(128, kernel_size=4,strides=(2,2), padding = \"same\", kernel_initializer=init))\n",
    "    #discriminator.add(BatchNormalization())\n",
    "    #discriminator.add(GaussianNoise(0.2))\n",
    "    discriminator.add(LeakyReLU(alpha=0.2))\n",
    "    #discriminator.add(Dropout(0.2))\n",
    "\n",
    "    discriminator.add(Flatten())\n",
    "    #discriminator.add(Dense(1, activation='sigmoid'))\n",
    "    discriminator.add(Dense(1, activation='linear'))\n",
    "\n",
    "    return discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "impressive-buddy",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-14T01:05:23.789352Z",
     "iopub.status.busy": "2021-06-14T01:05:23.788427Z",
     "iopub.status.idle": "2021-06-14T01:05:24.247770Z",
     "shell.execute_reply": "2021-06-14T01:05:24.248406Z",
     "shell.execute_reply.started": "2021-06-14T00:59:57.944131Z"
    },
    "papermill": {
     "duration": 0.49023,
     "end_time": "2021-06-14T01:05:24.248602",
     "exception": false,
     "start_time": "2021-06-14T01:05:23.758372",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# For TPU Training\n",
    "with strategy.scope():\n",
    "    discriminator_model = image_discriminator()\n",
    "    discriminator_model.summary()\n",
    "\n",
    "# For GPU Training\n",
    "\"\"\"\n",
    "discriminator_model = image_discriminator()\n",
    "discriminator_model.summary()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "peaceful-roman",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-14T01:05:24.302918Z",
     "iopub.status.busy": "2021-06-14T01:05:24.302160Z",
     "iopub.status.idle": "2021-06-14T01:05:24.306182Z",
     "shell.execute_reply": "2021-06-14T01:05:24.306696Z",
     "shell.execute_reply.started": "2021-06-14T00:56:48.764619Z"
    },
    "papermill": {
     "duration": 0.034908,
     "end_time": "2021-06-14T01:05:24.306883",
     "exception": false,
     "start_time": "2021-06-14T01:05:24.271975",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fiscal-adjustment",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-14T01:05:24.365920Z",
     "iopub.status.busy": "2021-06-14T01:05:24.365130Z",
     "iopub.status.idle": "2021-06-14T01:05:24.368111Z",
     "shell.execute_reply": "2021-06-14T01:05:24.367568Z",
     "shell.execute_reply.started": "2021-06-14T01:00:07.960247Z"
    },
    "papermill": {
     "duration": 0.037124,
     "end_time": "2021-06-14T01:05:24.368280",
     "exception": false,
     "start_time": "2021-06-14T01:05:24.331156",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import random\n",
    "from numpy.random import choice\n",
    "\n",
    "def load_real_data(dataset, n_samples):\n",
    "  ix = np.random.randint(0, dataset.shape[0], n_samples)\n",
    "  X = dataset[ix]\n",
    "  y = -np.ones((n_samples, 1))\n",
    "  return X,y\n",
    "\n",
    "def load_fake_data(n_samples):\n",
    "  X = np.random.rand(64 * 64 * 3 * n_samples)\n",
    "  X = -1 + X * 2\n",
    "  X = X.reshape((n_samples, 64,64,3))\n",
    "  y = np.ones((n_samples, 1))\n",
    "  return X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "professional-parish",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-14T01:05:24.427909Z",
     "iopub.status.busy": "2021-06-14T01:05:24.426783Z",
     "iopub.status.idle": "2021-06-14T01:05:24.444440Z",
     "shell.execute_reply": "2021-06-14T01:05:24.443802Z",
     "shell.execute_reply.started": "2021-06-14T01:00:10.741624Z"
    },
    "papermill": {
     "duration": 0.051951,
     "end_time": "2021-06-14T01:05:24.444600",
     "exception": false,
     "start_time": "2021-06-14T01:05:24.392649",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Resource: https://keras.io/examples/generative/wgan_gp/#create-the-wgangp-model\n",
    "class WGAN(keras.Model):\n",
    "    def __init__(\n",
    "            self,\n",
    "            discriminator,\n",
    "            generator,\n",
    "            latent_dim,\n",
    "            discriminator_extra_steps=5,\n",
    "            gp_weight=10.0,\n",
    "        ):\n",
    "            super(WGAN, self).__init__()\n",
    "            self.discriminator = discriminator\n",
    "            self.generator = generator\n",
    "            self.latent_dim = latent_dim\n",
    "            self.d_steps = discriminator_extra_steps\n",
    "            self.gp_weight = gp_weight\n",
    "    \n",
    "    # For TPU Training\n",
    "    \n",
    "    def compile(self, d_optimizer, g_optimizer, d_loss_fn, g_loss_fn, steps_per_execution):\n",
    "        super(WGAN, self).compile()\n",
    "        self.d_optimizer = d_optimizer\n",
    "        self.g_optimizer = g_optimizer\n",
    "        self.d_loss_fn = d_loss_fn\n",
    "        self.g_loss_fn = g_loss_fn\n",
    "        self.steps_per_execution = steps_per_execution\n",
    "    \n",
    "    # For GPU Training\n",
    "    \"\"\"\n",
    "    def compile(self, d_optimizer, g_optimizer, d_loss_fn, g_loss_fn):\n",
    "        super(WGAN, self).compile()\n",
    "        self.d_optimizer = d_optimizer\n",
    "        self.g_optimizer = g_optimizer\n",
    "        self.d_loss_fn = d_loss_fn\n",
    "        self.g_loss_fn = g_loss_fn\n",
    "    \"\"\"\n",
    "    def gradient_penalty(self, batch_size, real_images, fake_images):\n",
    "        \"\"\" Calculates the gradient penalty.\n",
    "\n",
    "        This loss is calculated on an interpolated image\n",
    "        and added to the discriminator loss.\n",
    "        \"\"\"\n",
    "        # Get the interpolated image\n",
    "        alpha = tf.random.normal([batch_size, 1, 1, 1], 0.0, 1.0)\n",
    "        diff = fake_images - real_images\n",
    "        interpolated = real_images + alpha * diff\n",
    "\n",
    "        with tf.GradientTape() as gp_tape:\n",
    "            gp_tape.watch(interpolated)\n",
    "            # 1. Get the discriminator output for this interpolated image.\n",
    "            pred = self.discriminator(interpolated, training=True)\n",
    "\n",
    "        # 2. Calculate the gradients w.r.t to this interpolated image.\n",
    "        grads = gp_tape.gradient(pred, [interpolated])[0]\n",
    "        # 3. Calculate the norm of the gradients.\n",
    "        norm = tf.sqrt(tf.reduce_sum(tf.square(grads), axis=[1, 2, 3]))\n",
    "        # For WGAN-GP\n",
    "        #gp = tf.reduce_mean((norm - 1.0) ** 2)\n",
    "        # For WGAN-LP\n",
    "        gp = tf.reduce_mean((tf.maximum(0., norm - 1.0)) ** 2)\n",
    "        return gp\n",
    "        \n",
    "    def train_step(self, real_images):\n",
    "        if isinstance(real_images, tuple):\n",
    "            real_images = real_images[0]\n",
    "\n",
    "        # Get the batch size\n",
    "        batch_size = tf.shape(real_images)[0]\n",
    "\n",
    "        # For each batch, we are going to perform the\n",
    "        # following steps as laid out in the original paper:\n",
    "        # 1. Train the generator and get the generator loss\n",
    "        # 2. Train the discriminator and get the discriminator loss\n",
    "        # 3. Calculate the gradient penalty\n",
    "        # 4. Multiply this gradient penalty with a constant weight factor\n",
    "        # 5. Add the gradient penalty to the discriminator loss\n",
    "        # 6. Return the generator and discriminator losses as a loss dictionary\n",
    "\n",
    "        # Train the discriminator first. The original paper recommends training\n",
    "        # the discriminator for `x` more steps (typically 5) as compared to\n",
    "        # one step of the generator. Here we will train it for 3 extra steps\n",
    "        # as compared to 5 to reduce the training time.\n",
    "        for i in range(self.d_steps):\n",
    "            # Get the latent vector\n",
    "            random_latent_vectors = tf.random.normal(\n",
    "                shape=(batch_size, self.latent_dim)\n",
    "            )\n",
    "            with tf.GradientTape() as tape:\n",
    "                # Generate fake images from the latent vector\n",
    "                fake_images = self.generator(random_latent_vectors, training=True)\n",
    "                # Get the logits for the fake images\n",
    "                fake_logits = self.discriminator(fake_images, training=True)\n",
    "                # Get the logits for the real images\n",
    "                real_logits = self.discriminator(real_images, training=True)\n",
    "\n",
    "                # Calculate the discriminator loss using the fake and real image logits\n",
    "                d_cost = self.d_loss_fn(real_img=real_logits, fake_img=fake_logits)\n",
    "                # Calculate the gradient penalty\n",
    "                gp = self.gradient_penalty(batch_size, real_images, fake_images)\n",
    "                # Add the gradient penalty to the original discriminator loss\n",
    "                d_loss = d_cost + gp * self.gp_weight\n",
    "\n",
    "            # Get the gradients w.r.t the discriminator loss\n",
    "            d_gradient = tape.gradient(d_loss, self.discriminator.trainable_variables)\n",
    "            # Update the weights of the discriminator using the discriminator optimizer\n",
    "            self.d_optimizer.apply_gradients(\n",
    "                zip(d_gradient, self.discriminator.trainable_variables)\n",
    "            )\n",
    "\n",
    "        # Train the generator\n",
    "        # Get the latent vector\n",
    "        random_latent_vectors = tf.random.normal(shape=(batch_size, self.latent_dim))\n",
    "        with tf.GradientTape() as tape:\n",
    "            # Generate fake images using the generator\n",
    "            generated_images = self.generator(random_latent_vectors, training=True)\n",
    "            # Get the discriminator logits for fake images\n",
    "            gen_img_logits = self.discriminator(generated_images, training=True)\n",
    "            # Calculate the generator loss\n",
    "            g_loss = self.g_loss_fn(gen_img_logits)\n",
    "\n",
    "        # Get the gradients w.r.t the generator loss\n",
    "        gen_gradient = tape.gradient(g_loss, self.generator.trainable_variables)\n",
    "        # Update the weights of the generator using the generator optimizer\n",
    "        self.g_optimizer.apply_gradients(\n",
    "            zip(gen_gradient, self.generator.trainable_variables)\n",
    "        )\n",
    "        return {\"d_loss\": d_loss, \"g_loss\": g_loss}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "noble-demonstration",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-14T01:05:24.560729Z",
     "iopub.status.busy": "2021-06-14T01:05:24.560008Z",
     "iopub.status.idle": "2021-06-14T01:05:24.564790Z",
     "shell.execute_reply": "2021-06-14T01:05:24.564246Z",
     "shell.execute_reply.started": "2021-06-14T01:00:15.648867Z"
    },
    "papermill": {
     "duration": 0.038571,
     "end_time": "2021-06-14T01:05:24.564940",
     "exception": false,
     "start_time": "2021-06-14T01:05:24.526369",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Every Xth epoch, generate and save 3 images. \n",
    "class GANMonitor(keras.callbacks.Callback):\n",
    "    def __init__(self, num_img=6, latent_dim=128):\n",
    "        self.num_img = num_img\n",
    "        self.latent_dim = latent_dim\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "\n",
    "        if (epoch + 1) % 20 == 0:\n",
    "          random_latent_vectors = np.random.rand(self.num_img, 100).astype(np.float32)\n",
    "          generated_images = self.model.generator(random_latent_vectors)\n",
    "\n",
    "          generated_images = (generated_images + 1) / 2.0\n",
    "\n",
    "          for i in range(self.num_img):\n",
    "            plt.imshow(generated_images[i])\n",
    "            plt.axis('off')\n",
    "            name = str(epoch) + '_generated_image_' + str(i) + '.png'\n",
    "            plt.savefig(name, bbox_inches='tight')\n",
    "            plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "israeli-things",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-14T01:05:24.695388Z",
     "iopub.status.busy": "2021-06-14T01:05:24.694672Z",
     "iopub.status.idle": "2021-06-14T07:47:48.162235Z",
     "shell.execute_reply": "2021-06-14T07:47:48.162830Z",
     "shell.execute_reply.started": "2021-06-14T01:00:18.788311Z"
    },
    "papermill": {
     "duration": 24143.509908,
     "end_time": "2021-06-14T07:47:48.163094",
     "exception": false,
     "start_time": "2021-06-14T01:05:24.653186",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# instantiating the model in the strategy scope creates the model on the TPU\n",
    "with strategy.scope():\n",
    "\n",
    "    lr_gen = 0.00005\n",
    "    lr_disc = 0.0002\n",
    "    beta1 = 0.5\n",
    "    gp = 10\n",
    "    dstep = 5\n",
    "\n",
    "    # Instantiate the optimizer for both networks\n",
    "    generator_optimizer = keras.optimizers.RMSprop(\n",
    "        learning_rate=lr_gen\n",
    "    )\n",
    "    discriminator_optimizer = keras.optimizers.RMSprop(\n",
    "        learning_rate=lr_disc\n",
    "    )\n",
    "\n",
    "    # Define the loss functions for the discriminator,\n",
    "    # which should be (fake_loss - real_loss).\n",
    "    # We will add the gradient penalty later to this loss function.\n",
    "    # tf.nn.compute_average_loss is required when using TPU.\n",
    "    # when using GPU, I used tf.reduce_mean instead. \n",
    "    \"\"\"\n",
    "    def discriminator_loss(real_img, fake_img):\n",
    "        real_loss = tf.reduce_mean(real_img)\n",
    "        fake_loss = tf.reduce_mean(fake_img)\n",
    "        return fake_loss - real_loss\n",
    "    \"\"\"\n",
    "\n",
    "    def discriminator_loss(real_img, fake_img):\n",
    "        real_loss = tf.nn.compute_average_loss(real_img, global_batch_size=128*8)\n",
    "        fake_loss = tf.nn.compute_average_loss(fake_img, global_batch_size=128*8)\n",
    "        return fake_loss - real_loss\n",
    "    \n",
    "    \"\"\"\n",
    "    # Define the loss functions for the generator.\n",
    "    def generator_loss(fake_img):\n",
    "        return -tf.reduce_mean(fake_img)\n",
    "    \"\"\"\n",
    "    \n",
    "    def generator_loss(fake_img):\n",
    "        return -tf.nn.compute_average_loss(fake_img, global_batch_size=128*8)\n",
    "    \n",
    "\n",
    "    # Set the number of epochs for trainining.\n",
    "    epochs = 2000\n",
    "\n",
    "    # Instantiate the customer `GANMonitor` Keras callback.\n",
    "    cbk = GANMonitor(num_img=3, latent_dim=100)\n",
    "\n",
    "\n",
    "    # Save the model after every epoch\n",
    "    save_locally = tf.saved_model.SaveOptions(experimental_io_device='/job:localhost')\n",
    "    now = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    filepath = \"./savedModels/\" + str(now) + \"_model/{epoch:02d}/\"\n",
    "    # If you want name to be static:\n",
    "    #filepath = \"./savedModels/xxx_model/{epoch:02d}/\"\n",
    "    savepoint = ModelCheckpoint(filepath, monitor='loss', verbose=0, save_best_only=False, save_freq=840, options=save_locally)\n",
    "\n",
    "    # Instantiate the WGAN model.\n",
    "    wgan = WGAN(\n",
    "        discriminator=discriminator_model,\n",
    "        generator=generator_model,\n",
    "        latent_dim=100,\n",
    "        discriminator_extra_steps=dstep,\n",
    "        gp_weight=gp\n",
    "    )\n",
    "\n",
    "    # Compile the WGAN model.\n",
    "    wgan.compile(\n",
    "        d_optimizer=discriminator_optimizer,\n",
    "        g_optimizer=generator_optimizer,\n",
    "        g_loss_fn=generator_loss,\n",
    "        d_loss_fn=discriminator_loss,\n",
    "        steps_per_execution=16\n",
    "    )\n",
    "\n",
    "    # Uncomment to load a model\n",
    "    #load_locally = tf.saved_model.LoadOptions(experimental_io_device='/job:localhost')\n",
    "    #wgan.load_weights(dest, options = load_locally)\n",
    "\n",
    "# Start training the model.\n",
    "print(\"starting training\")\n",
    "history = wgan.fit(images[:42000], batch_size=128*8, epochs=epochs, initial_epoch=0, callbacks=[cbk, savepoint])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 24235.874736,
   "end_time": "2021-06-14T07:48:44.060091",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-06-14T01:04:48.185355",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}